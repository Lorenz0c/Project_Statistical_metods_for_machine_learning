{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sigmoid_more_layer_same_nodes.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV752K1WaeSs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpveak7Dasbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "#Download the dataset\n",
        "URL='https://github.com/Horea94/Fruit-Images-Dataset/archive/master.zip'\n",
        "\n",
        "path_to_zip = tf.keras.utils.get_file('master.zip', origin=URL, extract=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r58U3px2av_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'Fruit-Images-Dataset-master')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'Training')\n",
        "validation_dir = os.path.join(PATH, 'Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEvGBvC7azPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Select the classes we are interested in.\n",
        "dir = pathlib.Path(validation_dir)\n",
        "\n",
        "CLASS_NAMES = np.array([item.name for item in dir.glob('*')])\n",
        "\n",
        "reg=re.compile('^(Apple|Banana|Plum|Pepper|Cherry|Grape|Tomato|Potato|Pear|Peach).*')\n",
        "\n",
        "temporary_class_names=[]\n",
        "\n",
        "for c in CLASS_NAMES:\n",
        "  if reg.match(c):\n",
        "    temporary_class_names.append(c)\n",
        "\n",
        "CLASS_NAMES_MOST_USED=temporary_class_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVbhWjPfa2G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "IMG_HEIGHT = 32\n",
        "IMG_WIDTH = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maC9D7I8a2zE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create a dataset containing the training set we are intrested in.\n",
        "list_ds=[]\n",
        "\n",
        "for c in CLASS_NAMES_MOST_USED:\n",
        "  train_dirs = os.path.join(train_dir, c)\n",
        "  train_dirs = pathlib.Path(train_dirs)\n",
        "  list_ds.append(tf.data.Dataset.list_files(str(train_dirs/'*')))\n",
        "\n",
        "train_ds=list_ds[0].concatenate(list_ds[1])\n",
        "for i in range(2,len(list_ds)):\n",
        "  train_ds=train_ds.concatenate(list_ds[i])\n",
        "\n",
        "#Count the number of example in the training set.\n",
        "num=0\n",
        "for j in train_ds.as_numpy_iterator():\n",
        "  num=num+1\n",
        "TRAINING_NUMBER=num\n",
        "\n",
        "\n",
        "#create a dataset containing the test set we are intrested in.\n",
        "list_ds=[]\n",
        "\n",
        "for c in CLASS_NAMES_MOST_USED:\n",
        "  test_dirs = os.path.join(validation_dir, c)\n",
        "  test_dirs = pathlib.Path(test_dirs)\n",
        "  list_ds.append(tf.data.Dataset.list_files(str(test_dirs/'*')))\n",
        "\n",
        "test_ds=list_ds[0].concatenate(list_ds[1])\n",
        "for i in range(2,len(list_ds)):\n",
        "  test_ds=test_ds.concatenate(list_ds[i])\n",
        "\n",
        "#Count the number of example in the test set.\n",
        "num=0\n",
        "for j in test_ds.as_numpy_iterator():\n",
        "  num=num+1\n",
        "TEST_NUMBER=num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EutEqtfFa_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#return the label associated to the image.\n",
        "def decode_label(parts):\n",
        "\n",
        "  if tf.strings.regex_full_match(parts, '.*Apple.*'):\n",
        "    return tf.constant(0)\n",
        "  if tf.strings.regex_full_match(parts, '.*Banana.*'):\n",
        "    return tf.constant(1)\n",
        "  if tf.strings.regex_full_match(parts, '.*Plum.*'):\n",
        "    return tf.constant(2)\n",
        "  if tf.strings.regex_full_match(parts, '.*Pepper.*'):\n",
        "    return tf.constant(3)\n",
        "  if tf.strings.regex_full_match(parts, '.*Cherry.*'):\n",
        "    return tf.constant(4)\n",
        "  if tf.strings.regex_full_match(parts, '.*Grape.*'):\n",
        "    return tf.constant(5)\n",
        "  if tf.strings.regex_full_match(parts, '.*Tomato.*'):\n",
        "    return tf.constant(6)\n",
        "  if tf.strings.regex_full_match(parts, '.*Potato.*'):\n",
        "    return tf.constant(7)\n",
        "  if tf.strings.regex_full_match(parts, '.*Pear.*'):\n",
        "    return tf.constant(8)\n",
        "  if tf.strings.regex_full_match(parts, '.*Peach.*'):\n",
        "    return tf.constant(9)\n",
        "  \n",
        "  return tf.constant(-1)\n",
        "\n",
        "#return the image.\n",
        "def decode_img(img):\n",
        "  # convert the compressed string to a 3D uint8 tensor\n",
        "  img = tf.image.decode_jpeg(img, channels=3)\n",
        "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
        "  # resize the image.\n",
        "  return tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
        "\n",
        "# return the image and the associated label given the file path.\n",
        "def process_path(file_path):\n",
        "  label = decode_label(file_path)\n",
        "  # load the raw data from the file as a string\n",
        "  img = tf.io.read_file(file_path)\n",
        "  img = decode_img(img)\n",
        "  return img, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_HtC4FnbDal",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "testing_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n",
        "\n",
        "# Shuffle the images in the training set, and divide the images in the two sets in batch.\n",
        "ds_for_training=training_ds.shuffle(TRAINING_NUMBER).batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "ds_for_test=testing_ds.batch(TEST_NUMBER).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEUmZV3EbERW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute the error of a predictor on a dataset using the zero one loss function.\n",
        "def zero_one_loss(model,ds):\n",
        "  probability_model = tf.keras.Sequential([model, \n",
        "                                         tf.keras.layers.Softmax()])\n",
        "\n",
        "  images,labels=next(iter(ds))\n",
        "  predictions = probability_model.predict(images)\n",
        "\n",
        "  zero_one_loss=0\n",
        "  for i in range(0,len(predictions)):\n",
        "    if labels[i]!=np.argmax(predictions[i]):\n",
        "      zero_one_loss=zero_one_loss+1\n",
        "\n",
        "  res=zero_one_loss/(len(predictions))\n",
        "  return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd9-F5znbWCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc512=[]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid', input_shape=(32, 32 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "for i in range(5):\n",
        "  model.fit(x=ds_for_training,\n",
        "            epochs=1)\n",
        "  \n",
        "  test_loss=zero_one_loss(model,ds_for_test)\n",
        "\n",
        "  acc512.append(test_loss)\n",
        "  print('epoch: ',i+1)\n",
        "  print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ro0_VMTd6c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc256=[]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid', input_shape=(32, 32 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(256, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "for i in range(5):\n",
        "  model.fit(x=ds_for_training,\n",
        "            epochs=1)\n",
        "\n",
        "  test_loss=zero_one_loss(model,ds_for_test)\n",
        "\n",
        "  acc256.append(test_loss)\n",
        "  print('epoch: ',i+1)\n",
        "  print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-5uatIQeyQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc128=[]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid', input_shape=(32, 32 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(128, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "for i in range(5):\n",
        "  model.fit(x=ds_for_training,\n",
        "            epochs=1)\n",
        "\n",
        "  test_loss=zero_one_loss(model,ds_for_test)\n",
        "\n",
        "  acc128.append(test_loss)\n",
        "  print('epoch: ',i+1)\n",
        "  print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16Q1ZiwAfoQu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc64=[]\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='sigmoid', input_shape=(32, 32 ,3)),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='sigmoid'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
        "    tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "for i in range(5):\n",
        "  model.fit(x=ds_for_training,\n",
        "            epochs=1)\n",
        "\n",
        "  test_loss=zero_one_loss(model,ds_for_test)\n",
        "\n",
        "  acc64.append(test_loss)\n",
        "  print('epoch: ',i+1)\n",
        "  print(test_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zanlyTKXoXh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the results\n",
        "epochs_range = range(1,6)\n",
        "\n",
        "plt.figure(figsize=(4, 2))\n",
        "plt.plot(epochs_range, acc512, label='Test Error 512-1')\n",
        "plt.plot(epochs_range, acc256, label='Test Error 256-2')\n",
        "plt.plot(epochs_range, acc128, label='Test Error 128-4')\n",
        "plt.plot(epochs_range, acc64, label='Test Error 64-8')\n",
        "plt.legend(loc='lower left', prop={'size': 6})\n",
        "plt.ylabel('Test error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.title('Test error')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}